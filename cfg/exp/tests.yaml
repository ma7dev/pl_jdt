name: test
# trainer
# devices: [0,1]
# devices: [0]
val_check_interval: 1.0
check_val_every_n_epoch: 1
accumulate_grad_batches: 1

# model
model:
  backbone:
    freeze: False
    trainable_backbone_layers: 3

  detector:
    freeze: False
    model: faster_rcnn

  tracker:
    # freeze: False
    freeze: False
    loss: bce
    model: lstm
    input_size: 256
    num_layers: 2

# hyperparams
max_epochs: 2
train:
  batch_size: 128
  optim:
    optimizer: sgd
    scheduler: step
    lr: 0.01
    momentum: 0.5
    step_size: 10
    weight_decay: 
    gamma: 0.1
val:
  batch_size: 128

# dataset
batch_sampler_type: default
num_workers: 4
seq:
  train:
    - MOT17-02
    - MOT17-04
    - MOT17-05
    - MOT17-10
    - MOT17-11
    - MOT17-13
  val:
    - MOT17-09

# loggers
wandb: False
tb: False
# csv: True

# callbacks
checkpoints:
  every_n_epochs: 1
  mintor: val/epoch/loss
# device_stats_monitor: True
# early_stopping:
#   monitor: val/epoch/loss
#   patience: 3
# model_summary:
#   max_path: 1

# debug
fast_dev_run: True
profiler: null
overfit_batches: 0
num_sanity_val_steps: 2

# reproducibility
deterministic: False
benchmark: False